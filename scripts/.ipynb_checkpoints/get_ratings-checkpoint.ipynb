{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df = pd.read_excel('../datasets/The Ramen Rater - The Big List.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import requests\n",
    "\n",
    "# get the ratings while preserving the link to the reviews\n",
    "\n",
    "url = 'http://www.theramenrater.com/resources-2/the-list/'\n",
    "r = requests.get(url)\n",
    "sp = bs.BeautifulSoup(r.content, 'lxml')\n",
    "tb = sp.find_all('table')[0] \n",
    "df = pd.read_html(str(tb),encoding='utf-8', attrs = {'id': 'myTable'}, header=0)[0]\n",
    "df['href'] = [tag.get('href') for tag in tb.find_all('a')]\n",
    "df.set_index('Review #', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Style</th>\n",
       "      <th>Country</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Top Ten</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>KOKA</td>\n",
       "      <td>Original Chicken Flavor</td>\n",
       "      <td>Pack</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theramenrater.com/2018/01/02/2674-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Nissin</td>\n",
       "      <td>Demae Ramen Bar Noodle Hokkaido Miso Tonkotsu ...</td>\n",
       "      <td>Pack</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theramenrater.com/2018/01/01/2673-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Wei Lih</td>\n",
       "      <td>Roast Beef Stew Noodle</td>\n",
       "      <td>Pack</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theramenrater.com/2017/12/31/2672-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>Acecook</td>\n",
       "      <td>Mochi Mochi Yakisoba</td>\n",
       "      <td>Cup</td>\n",
       "      <td>Japan</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theramenrater.com/2017/12/30/2671-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Nongshim</td>\n",
       "      <td>Kimchi Ramyun</td>\n",
       "      <td>Bowl</td>\n",
       "      <td>China</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.theramenrater.com/2017/12/29/2670-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                            Variety Style  \\\n",
       "Review #                                                                      \n",
       "2674          KOKA                            Original Chicken Flavor  Pack   \n",
       "2673        Nissin  Demae Ramen Bar Noodle Hokkaido Miso Tonkotsu ...  Pack   \n",
       "2672       Wei Lih                             Roast Beef Stew Noodle  Pack   \n",
       "2671       Acecook                               Mochi Mochi Yakisoba   Cup   \n",
       "2670      Nongshim                                      Kimchi Ramyun  Bowl   \n",
       "\n",
       "            Country Stars Top Ten  \\\n",
       "Review #                            \n",
       "2674      Singapore   3.5     NaN   \n",
       "2673      Hong Kong     5     NaN   \n",
       "2672         Taiwan     5     NaN   \n",
       "2671          Japan   4.5     NaN   \n",
       "2670          China  3.75     NaN   \n",
       "\n",
       "                                                       href  \n",
       "Review #                                                     \n",
       "2674      https://www.theramenrater.com/2018/01/02/2674-...  \n",
       "2673      https://www.theramenrater.com/2018/01/01/2673-...  \n",
       "2672      https://www.theramenrater.com/2017/12/31/2672-...  \n",
       "2671      https://www.theramenrater.com/2017/12/30/2671-...  \n",
       "2670      https://www.theramenrater.com/2017/12/29/2670-...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = df['href'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, bs.Comment):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "def remove_features(word, tagger, lmtzr):\n",
    "    \"\"\"Returns a word after it has been checked to see if it is worth keeping\"\"\"\n",
    "    nltk.data.path.append(\"/opt/gmi/bd_userapps/shared/nltk_data\")\n",
    "    function_list = [remove_stop_words, remove_puncuation, remove_numbers, filter_tag_pos, lemmatize_word,\n",
    "                     remove_short_words]\n",
    "    # lowercase\n",
    "    word = word.lower()\n",
    "    # iterate through functions and stop if the word gets thrown out\n",
    "    for func in function_list:\n",
    "        if func == filter_tag_pos:\n",
    "            word, tagged_text = func(word, tagger)\n",
    "        elif func == lemmatize_word:\n",
    "            word = func(tagged_text, lmtzr)\n",
    "        else:\n",
    "            word = func(word)\n",
    "        if word.isspace() or word == '':\n",
    "            break\n",
    "    return word\n",
    "\n",
    "\n",
    "@jit\n",
    "def filter_tag_pos(word, tagger):\n",
    "    \"\"\"Tag Part of Speach keep only verbs, nouns and adjectives\"\"\"\n",
    "    # noun tags\n",
    "    nn_tags = ['NN', 'NNP', 'NNP', 'NNPS', 'NNS']\n",
    "    # adjectives\n",
    "    jj_tags = ['JJ', 'JJR', 'JJS']\n",
    "    # verbs\n",
    "    vb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "    nltk_tags = nn_tags + jj_tags + vb_tags\n",
    "    tagged_text = tagger.tag([word])\n",
    "    # word & tag tuple\n",
    "    if tagged_text[0][1] not in nltk_tags:\n",
    "        word = ''\n",
    "    return word, tagged_text\n",
    "\n",
    "\n",
    "@jit\n",
    "def lemmatize_word(tagged_text, lmtzr):\n",
    "    if tagged_text[0][1][0].lower() == 'v':\n",
    "        word = lmtzr.lemmatize(tagged_text[0][0], pos='v')\n",
    "    elif tagged_text[0][1][0].lower() == 'n':\n",
    "        word = lmtzr.lemmatize(tagged_text[0][0], pos='n')\n",
    "    else:\n",
    "        word = tagged_text[0][0]\n",
    "    return word\n",
    "\n",
    "\n",
    "@jit\n",
    "def remove_short_words(word):\n",
    "    if len(word) < 3:\n",
    "        word = ''\n",
    "    return word\n",
    "\n",
    "\n",
    "@jit\n",
    "def remove_stop_words(word):\n",
    "    \"\"\"take a word and check it against the common stop words list from NLTK\"\"\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    if word in stops:\n",
    "        word = ''\n",
    "    return word\n",
    "\n",
    "\n",
    "@jit\n",
    "def remove_puncuation(word):\n",
    "    # compile regex\n",
    "    punc_re = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation\n",
    "    word = punc_re.sub('', word)\n",
    "    return word\n",
    "\n",
    "\n",
    "@jit\n",
    "def remove_numbers(word):\n",
    "    # compile regex\n",
    "    num_re = re.compile('(\\\\d+)')\n",
    "    # remove numbers\n",
    "    word = num_re.sub('', word)\n",
    "    return word\n",
    "\n",
    "\n",
    "def text_cleaner(raw_str, tagger, lmtzr):\n",
    "    \"\"\"Returns a cleaned row after removing words not needed\"\"\"\n",
    "    clean_words = []\n",
    "    for word in word_tokenize(raw_str):\n",
    "        clean_words.append(remove_features(word, tagger, lmtzr))\n",
    "    clean_str = \" \".join(map(str, clean_words))\n",
    "    # remove redundant spaces\n",
    "    clean_str = re.sub('\\s\\s+', ' ', clean_str)\n",
    "    return clean_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " amaze koka variety review complain sure hamper stock good thing let ease run variety try today chicken get cooked chicken let look koka oriental instant noodle original chicken flavour singapore package look meat free red dot denote suitable vegetarian prepare add noodle block boil water cook minute add sachet content stir enjoy noodle block soup base sachet light powder finish add hard boil egg salad cosmo mung bean sprout spring onion bake chicken noodle good decent gauge chew stronger backbone expect honest broth patent chicken flavor bad amaze decent chicken flavor instant noodle star ean bar code koka instant noodle flavour take poll disco chicken enjoy hour necessary \n"
     ]
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "tagger = PerceptronTagger()\n",
    "\n",
    "for review_url in review_list:\n",
    "    page = requests.get(review_url)\n",
    "    # get entry text\n",
    "    soup = bs.BeautifulSoup(page.content, 'html.parser')\n",
    "    entry = soup.findAll(\"div\", {\"class\": \"entry-content\"})[0].findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, entry)  \n",
    "    text_str = \" \".join(t.strip() for t in visible_texts)\n",
    "    # remove extra site specific repeated text\n",
    "    stop_phrases = ['Like this: Like',  'Loading...', 'See more related reviews', 'Spread the love', '( click to enlarge )']\n",
    "    for stop in stop_phrases:\n",
    "        text_str = text_str.replace(stop, '')\n",
    "    # begin NLP preprocessing\n",
    "    clean_str = text_cleaner(text_str, tagger, lmtzr)\n",
    "    print(clean_str)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
